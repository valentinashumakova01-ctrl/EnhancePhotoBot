import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
import numpy as np
import io
import urllib.request
from pathlib import Path
import time
import math
import gc

st.set_page_config(
    page_title="RealESRGAN - –°—Ç–∞–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è",
    page_icon="üõ°Ô∏è",
    layout="wide"
)

st.title("üõ°Ô∏è RealESRGAN - –°—Ç–∞–±–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞")

# –û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Ç–∞–∫–æ–π –∂–µ...

def safe_process_with_tiling(model, image, tile_size=128, overlap=16):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –æ—á–∏—Å—Ç–∫–æ–π –ø–∞–º—è—Ç–∏"""
    try:
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        max_input_size = 1024
        if max(image.size) > max_input_size:
            ratio = max_input_size / max(image.size)
            new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))
            image = image.resize(new_size, Image.Resampling.LANCZOS)
            st.warning(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–º–µ–Ω—å—à–µ–Ω–æ –¥–æ {new_size} –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
        img_np = np.array(image).astype(np.float32) / 255.0
        h, w = img_np.shape[:2]
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä
        out_h, out_w = h * 4, w * 4
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π –º–∞—Å—Å–∏–≤
        output = np.zeros((out_h, out_w, 3), dtype=np.float32)
        
        # –ú–∞–ª–µ–Ω—å–∫–∏–π —Ä–∞–∑–º–µ—Ä —Ç–∞–π–ª–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        tile_size = min(tile_size, 128)
        overlap = min(overlap, 16)
        
        tiles_x = math.ceil(w / tile_size)
        tiles_y = math.ceil(h / tile_size)
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i in range(tiles_y):
            for j in range(tiles_x):
                # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–∞–π–ª–∞
                x1 = j * tile_size
                y1 = i * tile_size
                x2 = min(x1 + tile_size, w)
                y2 = min(y1 + tile_size, h)
                
                status_text.text(f"–¢–∞–π–ª {i*tiles_x + j + 1}/{tiles_x * tiles_y}")
                
                if (x2 - x1) > 0 and (y2 - y1) > 0:
                    # –í—ã—Ä–µ–∑–∞–µ–º —Ç–∞–π–ª
                    tile = img_np[y1:y2, x1:x2]
                    
                    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π padding
                    tile_padded = np.pad(tile, 
                                       ((overlap, overlap), 
                                        (overlap, overlap), 
                                        (0, 0)), 
                                       mode='reflect')
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
                    tile_tensor = torch.from_numpy(tile_padded).permute(2, 0, 1).unsqueeze(0).float()
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                    with torch.no_grad():
                        tile_output = model(tile_tensor)
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ
                    tile_output_np = tile_output.squeeze().permute(1, 2, 0).cpu().numpy()
                    
                    # –£–±–∏—Ä–∞–µ–º overlap
                    overlap_scaled = overlap * 4
                    if tile_output_np.shape[0] > overlap_scaled * 2:
                        tile_output_cropped = tile_output_np[overlap_scaled:-overlap_scaled, 
                                                           overlap_scaled:-overlap_scaled]
                    else:
                        tile_output_cropped = tile_output_np
                    
                    # –ö–æ–ø–∏—Ä—É–µ–º
                    output[y1*4:y2*4, x1*4:x2*4] = tile_output_cropped
                    
                    # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å
                    del tile_tensor, tile_output, tile_output_np
                    gc.collect()
                
                # –ü—Ä–æ–≥—Ä–µ—Å—Å
                progress = (i * tiles_x + j + 1) / (tiles_x * tiles_y)
                progress_bar.progress(progress)
        
        progress_bar.empty()
        status_text.empty()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL
        output = np.clip(output, 0, 1) * 255
        return Image.fromarray(output.astype(np.uint8))
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)[:200]}")
        return None

# –í –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º safe_process_with_tiling –≤–º–µ—Å—Ç–æ process_with_tiling
