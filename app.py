import streamlit as st
import os
from pathlib import Path
import sys
from PIL import Image
import io
import cv2
import numpy as np
import torch
from basicsr.archs.rrdbnet_arch import RRDBNet
from realesrgan import RealESRGANer
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="AI Photo Enhancer Pro",
    page_icon="‚ú®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
MODELS_DIR = Path("models")
PORTRAIT_MODEL_SIZE = (128, 128)
PORTRAIT_OUTPUT_SCALE = 2
MAX_FILE_SIZE_MB = 20  # MB

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –º–æ–¥–µ–ª–µ–π
MODELS_DIR.mkdir(exist_ok=True)

# CSS —Å—Ç–∏–ª–∏
st.markdown("""
<style>
    .main-header {
        font-size: 2.8rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .status-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        padding: 20px;
        border-radius: 15px;
        color: white;
        margin: 10px 0;
    }
    .enhance-card {
        background: rgba(255, 255, 255, 0.1);
        padding: 20px;
        border-radius: 15px;
        margin: 10px 0;
        border-left: 5px solid #667eea;
    }
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 12px 24px;
        border-radius: 25px;
        font-weight: bold;
        font-size: 1.1rem;
        transition: all 0.3s;
    }
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
    }
    .image-container {
        border-radius: 10px;
        overflow: hidden;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.markdown('<h1 class="main-header">‚ú® AI Photo Enhancer Pro</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π Real-ESRGAN –∏ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π</p>', unsafe_allow_html=True)

# –ö–ª–∞—Å—Å –¥–ª—è –º–æ–¥–µ–ª–µ–π
class EnhancementModels:
    """–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏ —É–ª—É—á—à–µ–Ω–∏—è"""

    def __init__(self):
        self.models = {}
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        st.session_state['device'] = self.device

    def load_landscape_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ª–∞–Ω–¥—à–∞—Ñ—Ç–æ–≤"""
        try:
            model_path = MODELS_DIR / 'RealESRGAN_x4plus.pth'
            
            if not model_path.exists():
                st.error(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
                return None

            model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,
                           num_block=23, num_grow_ch=32, scale=4)

            upsampler = RealESRGANer(
                scale=4,
                model_path=str(model_path),
                model=model,
                tile=400,
                tile_pad=10,
                pre_pad=0,
                half=self.device.type != 'cpu',
                device=self.device
            )

            self.models['landscape'] = upsampler
            return upsampler

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –ª–∞–Ω–¥—à–∞—Ñ—Ç–æ–≤: {e}")
            return None

    def load_portrait_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤"""
        try:
            model_path = MODELS_DIR / 'enhanced_epoch_28_ratio_1.23.pth'
            
            if not model_path.exists():
                st.error(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
                return None

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏
            class ResidualBlock(torch.nn.Module):
                def __init__(self, channels):
                    super().__init__()
                    self.block = torch.nn.Sequential(
                        torch.nn.Conv2d(channels, channels, 3, padding=1),
                        torch.nn.ReLU(inplace=True),
                        torch.nn.Conv2d(channels, channels, 3, padding=1),
                    )
                def forward(self, x):
                    return x + self.block(x)

            class StrongGenerator(torch.nn.Module):
                def __init__(self):
                    super().__init__()
                    self.initial = torch.nn.Sequential(
                        torch.nn.Conv2d(3, 128, 3, padding=1),
                        torch.nn.ReLU(inplace=True)
                    )
                    self.res_blocks = torch.nn.Sequential(
                        ResidualBlock(128),
                        ResidualBlock(128),
                        ResidualBlock(128),
                        ResidualBlock(128),
                        ResidualBlock(128),
                        ResidualBlock(128)
                    )
                    self.final = torch.nn.Sequential(
                        torch.nn.Conv2d(128, 64, 3, padding=1),
                        torch.nn.ReLU(inplace=True),
                        torch.nn.Conv2d(64, 3, 3, padding=1)
                    )
                def forward(self, x):
                    identity = x
                    x = self.initial(x)
                    x = self.res_blocks(x)
                    x = self.final(x)
                    return identity + 0.3 * x

            checkpoint = torch.load(str(model_path), map_location=self.device)
            model = StrongGenerator().to(self.device)
            model.load_state_dict(checkpoint['generator'])
            model.eval()
            model.input_size = PORTRAIT_MODEL_SIZE

            self.models['portrait'] = model
            return model

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤: {e}")
            return None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
@st.cache_resource
def init_models():
    models_manager = EnhancementModels()
    
    with st.spinner("üîÑ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª–∏..."):
        models_manager.load_landscape_model()
        models_manager.load_portrait_model()
    
    loaded = list(models_manager.models.keys())
    return models_manager, loaded

# –§—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
def prepare_for_portrait_model(img_array: np.ndarray, target_size: tuple = (128, 128)) -> np.ndarray:
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    h, w = img_array.shape[:2]

    if h > target_size[0] or w > target_size[1]:
        scale = min(target_size[0] / h, target_size[1] / w)
        new_h = int(h * scale)
        new_w = int(w * scale)
        resized = cv2.resize(img_array, (new_w, new_h), interpolation=cv2.INTER_AREA)
    else:
        scale = min(target_size[0] / h, target_size[1] / w)
        new_h = int(h * scale)
        new_w = int(w * scale)
        resized = cv2.resize(img_array, (new_w, new_h), interpolation=cv2.INTER_CUBIC)

    if new_h < target_size[0] or new_w < target_size[1]:
        pad_h = target_size[0] - new_h
        pad_w = target_size[1] - new_w

        pad_top = pad_h // 2
        pad_bottom = pad_h - pad_top
        pad_left = pad_w // 2
        pad_right = pad_w - pad_left

        resized = cv2.copyMakeBorder(resized,
                                    pad_top, pad_bottom,
                                    pad_left, pad_right,
                                    cv2.BORDER_REFLECT)

    return resized

def enhance_portrait_model_inference(model, img_array: np.ndarray) -> np.ndarray:
    """–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    try:
        original_h, original_w = img_array.shape[:2]
        img_prepared = prepare_for_portrait_model(img_array, PORTRAIT_MODEL_SIZE)

        img_tensor = torch.from_numpy(img_prepared).permute(2, 0, 1).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0).to(model.device)

        with torch.no_grad():
            output_tensor = model(img_tensor)

        output_tensor = output_tensor.squeeze(0).permute(1, 2, 0)
        output = (output_tensor.cpu().numpy() * 255.0).astype(np.uint8)

        h, w = output.shape[:2]
        target_h, target_w = PORTRAIT_MODEL_SIZE
        pad_h = h - target_h
        pad_w = w - target_w

        if pad_h > 0 or pad_w > 0:
            start_h = pad_h // 2 if pad_h > 0 else 0
            start_w = pad_w // 2 if pad_w > 0 else 0
            end_h = h - (pad_h - start_h) if pad_h > 0 else h
            end_w = w - (pad_w - start_w) if pad_w > 0 else w
            output = output[start_h:end_h, start_w:end_w]

        if PORTRAIT_OUTPUT_SCALE > 1:
            scaled_h = output.shape[0] * PORTRAIT_OUTPUT_SCALE
            scaled_w = output.shape[1] * PORTRAIT_OUTPUT_SCALE
            output = cv2.resize(output, (scaled_w, scaled_h), interpolation=cv2.INTER_CUBIC)

        result_h, result_w = output.shape[:2]
        if result_h < original_h and result_w < original_w:
            scale_h = original_h / result_h
            scale_w = original_w / result_w
            scale = max(scale_h, scale_w)
            if scale > 1:
                new_h = int(result_h * scale)
                new_w = int(result_w * scale)
                output = cv2.resize(output, (new_w, new_h), interpolation=cv2.INTER_CUBIC)

        return output

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≤ –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
        raise

def enhance_image_basic(img_array: np.ndarray, scale: int = 2, sharpness: float = 1.3) -> Image.Image:
    """–ë–∞–∑–æ–≤–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (fallback)"""
    try:
        h, w = img_array.shape[:2]
        enhanced = cv2.resize(img_array, (w * scale, h * scale),
                             interpolation=cv2.INTER_CUBIC)

        if sharpness > 1.0:
            gaussian = cv2.GaussianBlur(enhanced, (0, 0), 3)
            enhanced = cv2.addWeighted(enhanced, sharpness, gaussian, 1 - sharpness, 0)

        lab = cv2.cvtColor(enhanced, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        enhanced = cv2.cvtColor(cv2.merge([l, a, b]), cv2.COLOR_LAB2RGB)

        enhanced = cv2.fastNlMeansDenoisingColored(enhanced, None, 5, 5, 7, 21)

        return Image.fromarray(enhanced)

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≤ –±–∞–∑–æ–≤–æ–º —É–ª—É—á—à–µ–Ω–∏–∏: {e}")
        h, w = img_array.shape[:2]
        enhanced = cv2.resize(img_array, (w * scale, h * scale),
                             interpolation=cv2.INTER_LINEAR)
        return Image.fromarray(enhanced)

def enhance_image_advanced(image: Image.Image, models_manager, enhancement_type: str = 'auto') -> Image.Image:
    """–£–ª—É—á—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    try:
        img_array = np.array(image)

        if enhancement_type == 'landscape':
            model = models_manager.models.get('landscape')
            if model is not None:
                output, _ = model.enhance(img_array, outscale=4)
                return Image.fromarray(output)
            else:
                return enhance_image_basic(img_array, scale=4, sharpness=1.5)

        elif enhancement_type == 'portrait':
            model = models_manager.models.get('portrait')
            if model is not None:
                output = enhance_portrait_model_inference(model, img_array)
                return Image.fromarray(output)
            else:
                return enhance_image_basic(img_array, scale=2, sharpness=1.2)

        else:  # auto
            height, width = img_array.shape[:2]
            aspect_ratio = width / height

            if aspect_ratio > 1.3:
                model = models_manager.models.get('landscape')
            else:
                model = models_manager.models.get('portrait')

            if model is not None:
                if model == models_manager.models.get('landscape'):
                    output, _ = model.enhance(img_array, outscale=4)
                else:
                    output = enhance_portrait_model_inference(model, img_array)
                return Image.fromarray(output)
            else:
                return enhance_image_basic(img_array)

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–º —É–ª—É—á—à–µ–Ω–∏–∏: {e}")
        return enhance_image_basic(np.array(image))

def save_image(image, format='PNG'):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ bytes"""
    img_byte_arr = io.BytesIO()
    image.save(img_byte_arr, format=format)
    return img_byte_arr.getvalue()

# –°–∞–π–¥–±–∞—Ä
with st.sidebar:
    st.title("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    st.subheader("–¢–∏–ø —É–ª—É—á—à–µ–Ω–∏—è")
    enhancement_type = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:",
        ["ü§ñ –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "üé≠ –ü–æ—Ä—Ç—Ä–µ—Ç", "üåÑ –ü–µ–π–∑–∞–∂"],
        index=0
    )
    
    enhancement_type = enhancement_type.split(" ")[1].lower()
    
    st.divider()
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö
    st.subheader("üß† –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö")
    
    if 'models_manager' in st.session_state:
        loaded_models = st.session_state.models_loaded
        if loaded_models:
            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(loaded_models)}")
            for model in loaded_models:
                if model == 'landscape':
                    st.info("üåÑ Real-ESRGAN (–ª–∞–Ω–¥—à–∞—Ñ—Ç—ã, x4 —É–≤–µ–ª–∏—á–µ–Ω–∏–µ)")
                elif model == 'portrait':
                    st.info(f"üé≠ –ö–∞—Å—Ç–æ–º–Ω–∞—è –º–æ–¥–µ–ª—å (–ø–æ—Ä—Ç—Ä–µ—Ç—ã, –≤—Ö–æ–¥: {PORTRAIT_MODEL_SIZE[0]}x{PORTRAIT_MODEL_SIZE[1]}, –≤—ã—Ö–æ–¥ x{PORTRAIT_OUTPUT_SCALE})")
        else:
            st.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    
    st.divider()
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
    st.subheader("üíª –°–∏—Å—Ç–µ–º–∞")
    if 'device' in st.session_state:
        device_name = "GPU üöÄ" if str(st.session_state.device) == "cuda" else "CPU ‚ö°"
        st.write(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_name}")
    
    st.write(f"–ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {MAX_FILE_SIZE_MB}MB")

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
tab1, tab2, tab3 = st.tabs(["üñºÔ∏è –£–ª—É—á—à–µ–Ω–∏–µ —Ñ–æ—Ç–æ", "üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ", "‚ÑπÔ∏è –û —Å–µ—Ä–≤–∏—Å–µ"])

with tab1:
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–æ—Ç–æ
    uploaded_file = st.file_uploader(
        "üì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è",
        type=['jpg', 'jpeg', 'png', 'bmp', 'webp'],
        help=f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE_MB}MB"
    )
    
    if uploaded_file is not None:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
        file_size = len(uploaded_file.getvalue()) / (1024 * 1024)  # MB
        if file_size > MAX_FILE_SIZE_MB:
            st.error(f"‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({file_size:.1f}MB). –ú–∞–∫—Å–∏–º—É–º: {MAX_FILE_SIZE_MB}MB")
            st.stop()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = Image.open(uploaded_file).convert('RGB')
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üì∑ –û—Ä–∏–≥–∏–Ω–∞–ª")
            st.image(image, use_column_width=True)
            st.caption(f"–†–∞–∑–º–µ—Ä: {image.width}√ó{image.height} –ø–∏–∫—Å–µ–ª–µ–π")
        
        # –ö–Ω–æ–ø–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è
        if st.button("‚ú® –£–õ–£–ß–®–ò–¢–¨ –§–û–¢–û", type="primary", use_container_width=True):
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
            if 'models_manager' not in st.session_state:
                models_manager, loaded = init_models()
                st.session_state.models_manager = models_manager
                st.session_state.models_loaded = loaded
            else:
                models_manager = st.session_state.models_manager
            
            with st.spinner("üß† –ò–ò –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..."):
                progress_bar = st.progress(0)
                
                # –ò–º–∏—Ç–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                for percent_complete in range(100):
                    time.sleep(0.01)
                    progress_bar.progress(percent_complete + 1)
                
                # –£–ª—É—á—à–µ–Ω–∏–µ —Ñ–æ—Ç–æ
                enhanced_image = enhance_image_advanced(
                    image, 
                    models_manager, 
                    enhancement_type
                )
                
                progress_bar.empty()
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                with col2:
                    st.subheader("üöÄ –£–ª—É—á—à–µ–Ω–Ω–æ–µ")
                    st.image(enhanced_image, use_column_width=True)
                    st.caption(f"–ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {enhanced_image.width}√ó{enhanced_image.height} –ø–∏–∫—Å–µ–ª–µ–π")
                    
                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É–ª—É—á—à–µ–Ω–∏–∏
                    with st.expander("üìä –î–µ—Ç–∞–ª–∏ —É–ª—É—á—à–µ–Ω–∏—è"):
                        st.write(f"**–¢–∏–ø —É–ª—É—á—à–µ–Ω–∏—è:** {enhancement_type}")
                        st.write(f"**–ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä:** {image.width}√ó{image.height}")
                        st.write(f"**–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä:** {enhanced_image.width}√ó{enhanced_image.height}")
                        
                        if enhancement_type == 'portrait':
                            st.write(f"**–ú–æ–¥–µ–ª—å:** –ö–∞—Å—Ç–æ–º–Ω–∞—è CNN")
                            st.write(f"**–í—Ö–æ–¥ –º–æ–¥–µ–ª–∏:** {PORTRAIT_MODEL_SIZE[0]}√ó{PORTRAIT_MODEL_SIZE[1]}")
                            st.write(f"**–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–∞:** √ó{PORTRAIT_OUTPUT_SCALE}")
                        elif enhancement_type == 'landscape':
                            st.write(f"**–ú–æ–¥–µ–ª—å:** Real-ESRGAN")
                            st.write(f"**–£–≤–µ–ª–∏—á–µ–Ω–∏–µ:** √ó4")
                    
                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    enhanced_bytes = save_image(enhanced_image, 'PNG')
                    
                    st.download_button(
                        label="üíæ –°–ö–ê–ß–ê–¢–¨ –£–õ–£–ß–®–ï–ù–ù–û–ï –§–û–¢–û",
                        data=enhanced_bytes,
                        file_name="enhanced_photo.png",
                        mime="image/png",
                        type="primary",
                        use_container_width=True
                    )
                
                st.success("‚úÖ –§–æ—Ç–æ —É—Å–ø–µ—à–Ω–æ —É–ª—É—á—à–µ–Ω–æ!")
                st.balloons()

with tab2:
    st.header("üîÑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –î–û –∏ –ü–û–°–õ–ï")
    
    if uploaded_file is not None and 'enhanced_image' in locals():
        col_before, col_after = st.columns(2)
        
        with col_before:
            st.subheader("–î–û —É–ª—É—á—à–µ–Ω–∏—è")
            st.image(image, use_column_width=True)
        
        with col_after:
            st.subheader("–ü–û–°–õ–ï —É–ª—É—á—à–µ–Ω–∏—è")
            st.image(enhanced_image, use_column_width=True)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        st.divider()
        st.subheader("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è")
        
        col_stat1, col_stat2, col_stat3 = st.columns(3)
        
        with col_stat1:
            st.metric(
                "–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ",
                f"{image.width}√ó{image.height}",
                f"{enhanced_image.width}√ó{enhanced_image.height}"
            )
        
        with col_stat2:
            pixel_increase = ((enhanced_image.width * enhanced_image.height) / 
                            (image.width * image.height))
            st.metric(
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏–∫—Å–µ–ª–µ–π",
                f"{(image.width * image.height):,}",
                f"{(enhanced_image.width * enhanced_image.height):,}",
                delta=f"√ó{pixel_increase:.1f}"
            )
        
        with col_stat3:
            st.metric(
                "–ö–∞—á–µ—Å—Ç–≤–æ",
                "–ò—Å—Ö–æ–¥–Ω–æ–µ",
                "–£–ª—É—á—à–µ–Ω–Ω–æ–µ",
                delta="–ü–æ–≤—ã—à–µ–Ω–æ"
            )

with tab3:
    st.header("‚ÑπÔ∏è –û —Å–µ—Ä–≤–∏—Å–µ")
    
    st.markdown("""
    ### ‚ú® –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞
    
    **üéØ –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
    - –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
    - –£–ª—É—á—à–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ —Ä–µ–∑–∫–æ—Å—Ç–∏
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
    
    **üß† –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**
    
    1. **Real-ESRGAN** –¥–ª—è –ø–µ–π–∑–∞–∂–µ–π:
       - –£–≤–µ–ª–∏—á–µ–Ω–∏–µ √ó4 (–¥–æ 4K)
       - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π
       - –£–ª—É—á—à–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç—É—Ä
    
    2. **–ö–∞—Å—Ç–æ–º–Ω–∞—è CNN-–º–æ–¥–µ–ª—å** –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤:
       - –í—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä: 128√ó128 –ø–∏–∫—Å–µ–ª–µ–π
       - –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–∞: √ó2
       - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ª–∏—Ü
    
    **üìä –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
    - –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ **–Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è**
    - –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –∏–ª–∏ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    
    ### üöÄ –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
    1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é
    2. –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø —É–ª—É—á—à–µ–Ω–∏—è (–∏–ª–∏ –æ—Å—Ç–∞–≤—å—Ç–µ –∞–≤—Ç–æ)
    3. –ù–∞–∂–º–∏—Ç–µ "–£–ª—É—á—à–∏—Ç—å —Ñ–æ—Ç–æ"
    4. –°–∫–∞—á–∞–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    
    ### üí° –°–æ–≤–µ—Ç—ã:
    - –î–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∂–∏–º "–ü–æ—Ä—Ç—Ä–µ—Ç"
    - –î–ª—è –ø–µ–π–∑–∞–∂–µ–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∂–∏–º "–ü–µ–π–∑–∞–∂"
    - "–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ" –ø–æ–¥–±–∏—Ä–∞–µ—Ç –º–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏—Å—Ö–æ–¥–Ω—ã–µ —Ñ–æ—Ç–æ —Ö–æ—Ä–æ—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
    """)
    
    st.divider()
    
    col_info1, col_info2, col_info3 = st.columns(3)
    
    with col_info1:
        st.markdown("""
        ### üé≠ –ü–æ—Ä—Ç—Ä–µ—Ç—ã
        - –£–ª—É—á—à–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π –ª–∏—Ü–∞
        - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
        - –£–ª—É—á—à–µ–Ω–∏–µ –∫–æ–∂–∏
        """)
    
    with col_info2:
        st.markdown("""
        ### üåÑ –ü–µ–π–∑–∞–∂–∏
        - –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –¥–æ 4K
        - –£–ª—É—á—à–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç—É—Ä
        - –¶–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è
        """)
    
    with col_info3:
        st.markdown("""
        ### üèôÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        - –£–ª—É—á—à–µ–Ω–∏–µ –ª–∏–Ω–∏–π
        - –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è
        - –†–µ–∑–∫–æ—Å—Ç—å
        """)

# –§—É—Ç–µ—Ä
st.divider()
st.markdown("""
<div style="text-align: center; color: #666; padding: 20px;">
    <p>¬© 2024 AI Photo Enhancer Pro | Powered by Real-ESRGAN & Custom CNN Models</p>
    <p>Streamlit ¬∑ PyTorch ¬∑ OpenCV</p>
</div>
""", unsafe_allow_html=True)
