import streamlit as st
import os
from pathlib import Path
from PIL import Image
import io
import cv2
import numpy as np
import torch
import torch.nn as nn
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="AI Photo Enhancer",
    page_icon="‚ú®",
    layout="wide"
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
MODELS_DIR = Path("models")
MAX_FILE_SIZE_MB = 20

# CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

st.markdown('<h1 class="main-header">‚ú® AI Photo Enhancer</h1>', unsafe_allow_html=True)

# ================== –ü–†–û–°–¢–´–ï –ú–û–î–ï–õ–ò ==================

# –ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ (inline)
class SimplePortraitModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 3, 3, padding=1)
        )
    
    def forward(self, x):
        return x + 0.2 * self.net(x)

# ================== –ü–†–û–°–¢–ê–Ø –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô ==================

def load_models_simple():
    """–ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π"""
    models = {}
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º Real-ESRGAN
    realesrgan_path = MODELS_DIR / 'RealESRGAN_x4plus.pth'
    if realesrgan_path.exists():
        try:
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å Real-ESRGAN –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            try:
                from basicsr.archs.rrdbnet_arch import RRDBNet
                from realesrgan import RealESRGANer
                
                model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,
                               num_block=23, num_grow_ch=32, scale=4)
                
                upsampler = RealESRGANer(
                    scale=4,
                    model_path=str(realesrgan_path),
                    model=model,
                    tile=400,
                    tile_pad=10,
                    pre_pad=0,
                    half=device.type != 'cpu',
                    device=device
                )
                models['landscape'] = upsampler
                st.success("‚úÖ Real-ESRGAN –∑–∞–≥—Ä—É–∂–µ–Ω")
            except ImportError:
                st.warning("‚ö†Ô∏è Real-ESRGAN –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Real-ESRGAN: {e}")
    else:
        st.warning("‚ö†Ô∏è Real-ESRGAN —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # 2. –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤
    portrait_path = MODELS_DIR / 'enhanced_epoch_28_ratio_1.23.pth'
    if portrait_path.exists():
        try:
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å
            model = SimplePortraitModel()
            
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Å–∞
            checkpoint = torch.load(str(portrait_path), map_location=device)
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–ª—é—á–∏ –≤ checkpoint
            if 'generator' in checkpoint:
                model.load_state_dict(checkpoint['generator'])
            elif 'model' in checkpoint:
                model.load_state_dict(checkpoint['model'])
            elif 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'])
            else:
                # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞–ø—Ä—è–º—É—é
                model.load_state_dict(checkpoint)
            
            model.to(device)
            model.eval()
            models['portrait'] = model
            st.success("‚úÖ –ú–æ–¥–µ–ª—å –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤: {e}")
            st.write(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {str(e)}")
    else:
        st.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    return models, device

# ================== –ü–†–û–°–¢–û–ô –ò–ù–¢–ï–†–§–ï–ô–° ==================

# –°–∞–π–¥–±–∞—Ä
with st.sidebar:
    st.title("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    st.subheader("üß† –ú–æ–¥–µ–ª–∏")
    
    # –ö–Ω–æ–ø–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π
    if st.button("üîÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏", use_container_width=True):
        if 'models' not in st.session_state:
            models, device = load_models_simple()
            st.session_state.models = models
            st.session_state.device = device
            
            if models:
                st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models)}")
                for name in models.keys():
                    st.write(f"‚Ä¢ {name}")
            else:
                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å
    if 'models' in st.session_state:
        st.success(f"‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(st.session_state.models)}")
    else:
        st.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    
    st.divider()
    
    st.subheader("–¢–∏–ø —É–ª—É—á—à–µ–Ω–∏—è")
    model_type = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
        ["üé≠ –ü–æ—Ä—Ç—Ä–µ—Ç", "üåÑ –ü–µ–π–∑–∞–∂"],
        index=0
    )
    
    model_type = 'portrait' if "–ü–æ—Ä—Ç—Ä–µ—Ç" in model_type else 'landscape'

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
uploaded_file = st.file_uploader(
    "üì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ",
    type=['jpg', 'jpeg', 'png']
)

if uploaded_file:
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
    file_size = len(uploaded_file.getvalue()) / (1024 * 1024)
    if file_size > MAX_FILE_SIZE_MB:
        st.error(f"‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({file_size:.1f}MB)")
        st.stop()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image = Image.open(uploaded_file).convert('RGB')
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üì∑ –û—Ä–∏–≥–∏–Ω–∞–ª")
        st.image(image, use_column_width=True)
        st.caption(f"–†–∞–∑–º–µ—Ä: {image.width}√ó{image.height}")
    
    # –ö–Ω–æ–ø–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è
    if st.button("‚ú® –£–ª—É—á—à–∏—Ç—å —Ñ–æ—Ç–æ", type="primary", use_container_width=True):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ª–∏ –º–æ–¥–µ–ª–∏
        if 'models' not in st.session_state or not st.session_state.models:
            st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª–∏ (–∫–Ω–æ–ø–∫–∞ –≤ —Å–∞–π–¥–±–∞—Ä–µ)")
            st.stop()
        
        models = st.session_state.models
        device = st.session_state.device
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω—É—é –º–æ–¥–µ–ª—å
        if model_type not in models:
            st.error(f"‚ùå –ú–æ–¥–µ–ª—å '{model_type}' –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            st.write(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {list(models.keys())}")
            st.stop()
        
        model = models[model_type]
        
        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞..."):
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy
            img_array = np.array(image)
            
            try:
                if model_type == 'landscape' and hasattr(model, 'enhance'):
                    # Real-ESRGAN
                    output, _ = model.enhance(img_array, outscale=4)
                    enhanced_image = Image.fromarray(output)
                    method = "Real-ESRGAN"
                    
                elif model_type == 'portrait':
                    # –ü—Ä–æ—Å—Ç–∞—è –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è –º–æ–¥–µ–ª—å
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    h, w = img_array.shape[:2]
                    target_size = 256  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
                    
                    # –†–µ—Å–∞–π–∑–∏–º
                    scale = min(target_size / h, target_size / w)
                    new_h = int(h * scale)
                    new_w = int(w * scale)
                    resized = cv2.resize(img_array, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
                    img_tensor = torch.from_numpy(resized).permute(2, 0, 1).float() / 255.0
                    img_tensor = img_tensor.unsqueeze(0).to(device)
                    
                    # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
                    with torch.no_grad():
                        output_tensor = model(img_tensor)
                    
                    # –û–±—Ä–∞—Ç–Ω–æ –≤ numpy
                    output_tensor = output_tensor.squeeze(0).permute(1, 2, 0)
                    output = (output_tensor.cpu().numpy() * 255.0).astype(np.uint8)
                    
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É
                    output = cv2.resize(output, (image.width, image.height), interpolation=cv2.INTER_CUBIC)
                    enhanced_image = Image.fromarray(output)
                    method = "–ö–∞—Å—Ç–æ–º–Ω–∞—è CNN"
                    
                else:
                    # Fallback - –ø—Ä–æ—Å—Ç–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ
                    new_size = (image.width * 2, image.height * 2)
                    enhanced_image = image.resize(new_size, Image.Resampling.LANCZOS)
                    method = "–ü—Ä–æ—Å—Ç–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ"
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                with col2:
                    st.subheader("üöÄ –£–ª—É—á—à–µ–Ω–Ω–æ–µ")
                    st.image(enhanced_image, use_column_width=True)
                    st.caption(f"–†–∞–∑–º–µ—Ä: {enhanced_image.width}√ó{enhanced_image.height}")
                    
                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    buf = io.BytesIO()
                    enhanced_image.save(buf, format="PNG")
                    
                    st.download_button(
                        "üíæ –°–∫–∞—á–∞—Ç—å",
                        buf.getvalue(),
                        "enhanced.png",
                        "image/png",
                        use_container_width=True
                    )
                
                st.success(f"‚úÖ –§–æ—Ç–æ —É–ª—É—á—à–µ–Ω–æ —Å –ø–æ–º–æ—â—å—é {method}!")
                
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")

else:
    # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
    st.info("""
    ### üìã –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:
    1. **–ù–∞–∂–º–∏—Ç–µ "–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏"** –≤ —Å–∞–π–¥–±–∞—Ä–µ
    2. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ** 
    3. **–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –º–æ–¥–µ–ª–∏**
    4. **–ù–∞–∂–º–∏—Ç–µ "–£–ª—É—á—à–∏—Ç—å —Ñ–æ—Ç–æ"**
    
    ### üß† –ú–æ–¥–µ–ª–∏:
    - **üé≠ –ü–æ—Ä—Ç—Ä–µ—Ç:** –í–∞—à–∞ –∫–∞—Å—Ç–æ–º–Ω–∞—è –º–æ–¥–µ–ª—å
    - **üåÑ –ü–µ–π–∑–∞–∂:** Real-ESRGAN
    
    ### üìÅ –¢—Ä–µ–±—É–µ–º—ã–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ `models/`:
    1. `RealESRGAN_x4plus.pth`
    2. `enhanced_epoch_28_ratio_1.23.pth`
    """)

# –§—É—Ç–µ—Ä
st.divider()
st.caption("¬© 2024 AI Photo Enhancer | –ü—Ä–æ—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è")
