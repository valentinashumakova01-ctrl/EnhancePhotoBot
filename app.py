import streamlit as st
import os
from pathlib import Path
import sys
from PIL import Image
import io
import cv2
import numpy as np
import torch
from basicsr.archs.rrdbnet_arch import RRDBNet
from realesrgan import RealESRGANer
import time
import requests
from tqdm import tqdm

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="AI Photo Enhancer Pro",
    page_icon="‚ú®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
MODELS_DIR = Path("models")
PORTRAIT_MODEL_SIZE = (128, 128)
PORTRAIT_OUTPUT_SCALE = 2
MAX_FILE_SIZE_MB = 20  # MB

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –º–æ–¥–µ–ª–µ–π
MODELS_DIR.mkdir(exist_ok=True)

# CSS —Å—Ç–∏–ª–∏
st.markdown("""
<style>
    .main-header {
        font-size: 2.8rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 12px 24px;
        border-radius: 25px;
        font-weight: bold;
        font-size: 1.1rem;
    }
    .model-status {
        padding: 10px;
        border-radius: 5px;
        margin: 5px 0;
    }
    .model-loaded {
        background: #d4edda;
        border-left: 4px solid #28a745;
    }
    .model-missing {
        background: #f8d7da;
        border-left: 4px solid #dc3545;
    }
</style>
""", unsafe_allow_html=True)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.markdown('<h1 class="main-header">‚ú® AI Photo Enhancer Pro</h1>', unsafe_allow_html=True)

# ================== –ö–õ–ê–°–° –î–õ–Ø –ú–û–î–ï–õ–ï–ô ==================
class EnhancementModels:
    """–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏ —É–ª—É—á—à–µ–Ω–∏—è"""
    
    def __init__(self):
        self.models = {}
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        st.session_state['device'] = self.device
    
    def load_landscape_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Real-ESRGAN –¥–ª—è –ª–∞–Ω–¥—à–∞—Ñ—Ç–æ–≤"""
        try:
            model_path = MODELS_DIR / 'RealESRGAN_x4plus.pth'
            
            if not model_path.exists():
                return None
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = os.path.getsize(model_path) / (1024 * 1024)
            if file_size < 60:
                return None
            
            model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,
                           num_block=23, num_grow_ch=32, scale=4)
            
            upsampler = RealESRGANer(
                scale=4,
                model_path=str(model_path),
                model=model,
                tile=400,
                tile_pad=10,
                pre_pad=0,
                half=self.device.type != 'cpu',
                device=self.device
            )
            
            self.models['landscape'] = upsampler
            return upsampler
            
        except Exception as e:
            return None
    
    def load_portrait_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Å—Ç–æ–º–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤"""
        try:
            model_path = MODELS_DIR / 'enhanced_epoch_28_ratio_1.23.pth'
            
            if not model_path.exists():
                return None
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏
            class ResidualBlock(torch.nn.Module):
                def __init__(self, channels):
                    super().__init__()
                    self.block = torch.nn.Sequential(
                        torch.nn.Conv2d(channels, channels, 3, padding=1),
                        torch.nn.ReLU(inplace=True),
                        torch.nn.Conv2d(channels, channels, 3, padding=1),
                    )
                def forward(self, x):
                    return x + self.block(x)
            
            class StrongGenerator(torch.nn.Module):
                def __init__(self):
                    super().__init__()
                    self.initial = torch.nn.Sequential(
                        torch.nn.Conv2d(3, 128, 3, padding=1),
                        torch.nn.ReLU(inplace=True)
                    )
                    self.res_blocks = torch.nn.Sequential(
                        ResidualBlock(128),
                        ResidualBlock(128),
                        ResidualBlock(128),
                        ResidualBlock(128),
                        ResidualBlock(128),
                        ResidualBlock(128)
                    )
                    self.final = torch.nn.Sequential(
                        torch.nn.Conv2d(128, 64, 3, padding=1),
                        torch.nn.ReLU(inplace=True),
                        torch.nn.Conv2d(64, 3, 3, padding=1)
                    )
                def forward(self, x):
                    identity = x
                    x = self.initial(x)
                    x = self.res_blocks(x)
                    x = self.final(x)
                    return identity + 0.3 * x
            
            checkpoint = torch.load(str(model_path), map_location=self.device)
            model = StrongGenerator().to(self.device)
            model.load_state_dict(checkpoint['generator'])
            model.eval()
            model.input_size = PORTRAIT_MODEL_SIZE
            
            self.models['portrait'] = model
            return model
            
        except Exception as e:
            return None

# ================== –§–£–ù–ö–¶–ò–ò –ò–ù–§–ï–†–ï–ù–°–ê ==================
def prepare_for_portrait_model(img_array: np.ndarray, target_size: tuple = (128, 128)) -> np.ndarray:
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    h, w = img_array.shape[:2]
    
    if h > target_size[0] or w > target_size[1]:
        scale = min(target_size[0] / h, target_size[1] / w)
        new_h = int(h * scale)
        new_w = int(w * scale)
        resized = cv2.resize(img_array, (new_w, new_h), interpolation=cv2.INTER_AREA)
    else:
        scale = min(target_size[0] / h, target_size[1] / w)
        new_h = int(h * scale)
        new_w = int(w * scale)
        resized = cv2.resize(img_array, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
    
    if new_h < target_size[0] or new_w < target_size[1]:
        pad_h = target_size[0] - new_h
        pad_w = target_size[1] - new_w
        
        pad_top = pad_h // 2
        pad_bottom = pad_h - pad_top
        pad_left = pad_w // 2
        pad_right = pad_w - pad_left
        
        resized = cv2.copyMakeBorder(resized,
                                    pad_top, pad_bottom,
                                    pad_left, pad_right,
                                    cv2.BORDER_REFLECT)
    
    return resized

def run_portrait_model_inference(model, img_array: np.ndarray) -> np.ndarray:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    try:
        original_h, original_w = img_array.shape[:2]
        img_prepared = prepare_for_portrait_model(img_array, PORTRAIT_MODEL_SIZE)
        
        img_tensor = torch.from_numpy(img_prepared).permute(2, 0, 1).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0).to(model.device)
        
        with torch.no_grad():
            output_tensor = model(img_tensor)
        
        output_tensor = output_tensor.squeeze(0).permute(1, 2, 0)
        output = (output_tensor.cpu().numpy() * 255.0).astype(np.uint8)
        
        h, w = output.shape[:2]
        target_h, target_w = PORTRAIT_MODEL_SIZE
        pad_h = h - target_h
        pad_w = w - target_w
        
        if pad_h > 0 or pad_w > 0:
            start_h = pad_h // 2 if pad_h > 0 else 0
            start_w = pad_w // 2 if pad_w > 0 else 0
            end_h = h - (pad_h - start_h) if pad_h > 0 else h
            end_w = w - (pad_w - start_w) if pad_w > 0 else w
            output = output[start_h:end_h, start_w:end_w]
        
        if PORTRAIT_OUTPUT_SCALE > 1:
            scaled_h = output.shape[0] * PORTRAIT_OUTPUT_SCALE
            scaled_w = output.shape[1] * PORTRAIT_OUTPUT_SCALE
            output = cv2.resize(output, (scaled_w, scaled_h), interpolation=cv2.INTER_CUBIC)
        
        result_h, result_w = output.shape[:2]
        if result_h < original_h and result_w < original_w:
            scale_h = original_h / result_h
            scale_w = original_w / result_w
            scale = max(scale_h, scale_w)
            if scale > 1:
                new_h = int(result_h * scale)
                new_w = int(result_w * scale)
                output = cv2.resize(output, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
        
        return output
        
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –≤ –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")

def run_landscape_model_inference(model, img_array: np.ndarray) -> np.ndarray:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –ª–∞–Ω–¥—à–∞—Ñ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ (Real-ESRGAN)"""
    try:
        output, _ = model.enhance(img_array, outscale=4)
        return output
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –≤ –ª–∞–Ω–¥—à–∞—Ñ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")

# ================== –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –£–õ–£–ß–®–ï–ù–ò–Ø ==================
def enhance_with_model(image: Image.Image, model_type: str, models_manager) -> Image.Image:
    """–£–ª—É—á—à–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL –≤ numpy
    img_array = np.array(image)
    
    if model_type == 'portrait':
        model = models_manager.models.get('portrait')
        if model is None:
            raise Exception("–ú–æ–¥–µ–ª—å –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
        output_array = run_portrait_model_inference(model, img_array)
        return Image.fromarray(output_array)
    
    elif model_type == 'landscape':
        model = models_manager.models.get('landscape')
        if model is None:
            raise Exception("–ú–æ–¥–µ–ª—å –¥–ª—è –ª–∞–Ω–¥—à–∞—Ñ—Ç–æ–≤ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
        output_array = run_landscape_model_inference(model, img_array)
        return Image.fromarray(output_array)
    
    else:  # auto
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        height, width = img_array.shape[:2]
        aspect_ratio = width / height
        
        if aspect_ratio > 1.3:  # –®–∏—Ä–æ–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ = –ª–∞–Ω–¥—à–∞—Ñ—Ç
            model = models_manager.models.get('landscape')
            if model is None:
                raise Exception("–ú–æ–¥–µ–ª—å –¥–ª—è –ª–∞–Ω–¥—à–∞—Ñ—Ç–æ–≤ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            output_array = run_landscape_model_inference(model, img_array)
        else:  # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –∏–ª–∏ –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–µ = –ø–æ—Ä—Ç—Ä–µ—Ç
            model = models_manager.models.get('portrait')
            if model is None:
                raise Exception("–ú–æ–¥–µ–ª—å –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            output_array = run_portrait_model_inference(model, img_array)
        
        return Image.fromarray(output_array)

# ================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ==================
def save_image(image, format='PNG'):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ bytes"""
    img_byte_arr = io.BytesIO()
    image.save(img_byte_arr, format=format)
    return img_byte_arr.getvalue()

@st.cache_resource
def init_models():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π"""
    models_manager = EnhancementModels()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
    with st.spinner("üîÑ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª–∏..."):
        landscape_loaded = models_manager.load_landscape_model()
        portrait_loaded = models_manager.load_portrait_model()
    
    loaded_models = []
    if landscape_loaded:
        loaded_models.append('landscape')
    if portrait_loaded:
        loaded_models.append('portrait')
    
    return models_manager, loaded_models

# ================== –ò–ù–¢–ï–†–§–ï–ô–° ==================
# –°–∞–π–¥–±–∞—Ä
with st.sidebar:
    st.title("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    st.subheader("üß† –ú–æ–¥–µ–ª–∏ —É–ª—É—á—à–µ–Ω–∏—è")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π
    realesrgan_exists = (MODELS_DIR / 'RealESRGAN_x4plus.pth').exists()
    portrait_exists = (MODELS_DIR / 'enhanced_epoch_28_ratio_1.23.pth').exists()
    
    if realesrgan_exists:
        size = os.path.getsize(MODELS_DIR / 'RealESRGAN_x4plus.pth') / (1024 * 1024)
        st.markdown(f'<div class="model-status model-loaded">‚úÖ Real-ESRGAN: {size:.1f}MB</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="model-status model-missing">‚ùå Real-ESRGAN: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç</div>', unsafe_allow_html=True)
    
    if portrait_exists:
        size = os.path.getsize(MODELS_DIR / 'enhanced_epoch_28_ratio_1.23.pth') / (1024 * 1024)
        st.markdown(f'<div class="model-status model-loaded">‚úÖ –ú–æ–¥–µ–ª—å –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤: {size:.1f}MB</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="model-status model-missing">‚ùå –ú–æ–¥–µ–ª—å –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç</div>', unsafe_allow_html=True)
    
    st.divider()
    
    st.subheader("–¢–∏–ø —É–ª—É—á—à–µ–Ω–∏—è")
    enhancement_type = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:",
        ["ü§ñ –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "üé≠ –¢–æ–ª—å–∫–æ –ø–æ—Ä—Ç—Ä–µ—Ç", "üåÑ –¢–æ–ª—å–∫–æ –ø–µ–π–∑–∞–∂"],
        index=0,
        help="–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±–µ—Ä–µ—Ç –º–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É —Ñ–æ—Ç–æ"
    )
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–∏–ø –¥–ª—è –º–æ–¥–µ–ª–∏
    if "–ø–æ—Ä—Ç—Ä–µ—Ç" in enhancement_type.lower():
        model_type = 'portrait'
    elif "–ø–µ–π–∑–∞–∂" in enhancement_type.lower():
        model_type = 'landscape'
    else:
        model_type = 'auto'
    
    st.divider()
    
    st.subheader("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    device_name = "GPU üöÄ" if torch.cuda.is_available() else "CPU ‚ö°"
    st.write(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_name}")
    st.write(f"–ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {MAX_FILE_SIZE_MB}MB")

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.markdown('<p class="sub-header">–£–ª—É—á—à–µ–Ω–∏–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π</p>', unsafe_allow_html=True)

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–æ—Ç–æ
uploaded_file = st.file_uploader(
    "üì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è",
    type=['jpg', 'jpeg', 'png'],
    help=f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE_MB}MB"
)

if uploaded_file is not None:
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
    file_size = len(uploaded_file.getvalue()) / (1024 * 1024)
    if file_size > MAX_FILE_SIZE_MB:
        st.error(f"‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({file_size:.1f}MB)")
        st.stop()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image = Image.open(uploaded_file).convert('RGB')
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üì∑ –û—Ä–∏–≥–∏–Ω–∞–ª")
        st.image(image, use_column_width=True)
        st.caption(f"–†–∞–∑–º–µ—Ä: {image.width}√ó{image.height} –ø–∏–∫—Å–µ–ª–µ–π")
    
    # –ö–Ω–æ–ø–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è
    if st.button("‚ú® –£–õ–£–ß–®–ò–¢–¨ –§–û–¢–û", type="primary", use_container_width=True):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
        if 'models_manager' not in st.session_state:
            models_manager, loaded_models = init_models()
            st.session_state.models_manager = models_manager
            st.session_state.loaded_models = loaded_models
            
            if not loaded_models:
                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å!")
                st.stop()
            else:
                st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(loaded_models)}")
        
        models_manager = st.session_state.models_manager
        
        with st.spinner("üß† –ù–µ–π—Ä–æ—Å–µ—Ç—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..."):
            try:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫—É—é –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
                if model_type == 'auto':
                    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                    if image.width / image.height > 1.3:  # –®–∏—Ä–æ–∫–æ–µ
                        actual_model = 'landscape'
                        model_name = "Real-ESRGAN (–ø–µ–π–∑–∞–∂–∏)"
                    else:  # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –∏–ª–∏ –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–µ
                        actual_model = 'portrait'
                        model_name = "–ö–∞—Å—Ç–æ–º–Ω–∞—è CNN (–ø–æ—Ä—Ç—Ä–µ—Ç—ã)"
                else:
                    actual_model = model_type
                    model_name = "Real-ESRGAN" if model_type == 'landscape' else "–ö–∞—Å—Ç–æ–º–Ω–∞—è CNN"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞
                if actual_model not in models_manager.models:
                    available = list(models_manager.models.keys())
                    st.error(f"‚ùå –ú–æ–¥–µ–ª—å '{actual_model}' –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã: {available}")
                    st.stop()
                
                # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
                progress_bar = st.progress(0)
                for i in range(100):
                    time.sleep(0.01)
                    progress_bar.progress(i + 1)
                
                # –£–ª—É—á—à–∞–µ–º —Ñ–æ—Ç–æ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏
                enhanced_image = enhance_with_model(image, actual_model, models_manager)
                
                progress_bar.empty()
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                with col2:
                    st.subheader("üöÄ –£–ª—É—á—à–µ–Ω–Ω–æ–µ")
                    st.image(enhanced_image, use_column_width=True)
                    st.caption(f"–ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {enhanced_image.width}√ó{enhanced_image.height} –ø–∏–∫—Å–µ–ª–µ–π")
                    
                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É–ª—É—á—à–µ–Ω–∏–∏
                    with st.expander("üìä –î–µ—Ç–∞–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏", expanded=True):
                        st.write(f"**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å:** {model_name}")
                        st.write(f"**–¢–∏–ø —É–ª—É—á—à–µ–Ω–∏—è:** {enhancement_type}")
                        st.write(f"**–ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä:** {image.width}√ó{image.height}")
                        st.write(f"**–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä:** {enhanced_image.width}√ó{enhanced_image.height}")
                        
                        if actual_model == 'portrait':
                            st.write(f"**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** Residual CNN")
                            st.write(f"**–í—Ö–æ–¥ –º–æ–¥–µ–ª–∏:** {PORTRAIT_MODEL_SIZE[0]}√ó{PORTRAIT_MODEL_SIZE[1]}")
                            st.write(f"**–£–≤–µ–ª–∏—á–µ–Ω–∏–µ:** √ó{PORTRAIT_OUTPUT_SCALE}")
                        else:
                            st.write(f"**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** Real-ESRGAN")
                            st.write(f"**–£–≤–µ–ª–∏—á–µ–Ω–∏–µ:** √ó4")
                    
                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    enhanced_bytes = save_image(enhanced_image, 'PNG')
                    
                    st.download_button(
                        label="üíæ –°–ö–ê–ß–ê–¢–¨ –£–õ–£–ß–®–ï–ù–ù–û–ï –§–û–¢–û",
                        data=enhanced_bytes,
                        file_name="enhanced_photo.png",
                        mime="image/png",
                        type="primary",
                        use_container_width=True
                    )
                
                st.success(f"‚úÖ –§–æ—Ç–æ —É—Å–ø–µ—à–Ω–æ —É–ª—É—á—à–µ–Ω–æ —Å –ø–æ–º–æ—â—å—é {model_name}!")
                st.balloons()
                
                # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
                st.divider()
                st.subheader("üîÑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                
                compare_col1, compare_col2 = st.columns(2)
                with compare_col1:
                    st.image(image, caption="–î–û —É–ª—É—á—à–µ–Ω–∏—è", use_column_width=True)
                with compare_col2:
                    st.image(enhanced_image, caption="–ü–û–°–õ–ï —É–ª—É—á—à–µ–Ω–∏—è", use_column_width=True)
                
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏: {str(e)}")
                st.info("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –∏–ª–∏ –¥—Ä—É–≥–æ–π —Ç–∏–ø —É–ª—É—á—à–µ–Ω–∏—è")

else:
    # –î–æ–º–∞—à–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
    st.info("""
    ### üéØ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π:
    
    **üé≠ –ö–∞—Å—Ç–æ–º–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤:**
    - –£–ª—É—á—à–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π –ª–∏—Ü–∞ –∏ –∫–æ–∂–∏
    - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤
    - –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–æ—Ç–æ
    
    **üåÑ Real-ESRGAN –¥–ª—è –ø–µ–π–∑–∞–∂–µ–π:**
    - –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –≤ 4 —Ä–∞–∑–∞
    - –£–ª—É—á—à–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç—É—Ä –∏ –¥–µ—Ç–∞–ª–µ–π
    - –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è —à–∏—Ä–æ–∫–æ—Ñ–æ—Ä–º–∞—Ç–Ω—ã—Ö —Ñ–æ—Ç–æ
    
    ### üìã –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
    1. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ** —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é (–∫–Ω–æ–ø–∫–∞ –≤—ã—à–µ)
    2. **–í—ã–±–µ—Ä–∏—Ç–µ** —Ç–∏–ø —É–ª—É—á—à–µ–Ω–∏—è –≤ —Å–∞–π–¥–±–∞—Ä–µ
    3. **–ù–∞–∂–º–∏—Ç–µ** "–£–ª—É—á—à–∏—Ç—å —Ñ–æ—Ç–æ"
    4. **–°–∫–∞—á–∞–π—Ç–µ** —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    
    ### üí° –°–æ–≤–µ—Ç—ã:
    - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **"–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"** –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏
    - –î–ª—è **–ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤** –≤—ã–±–∏—Ä–∞–π—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ä–µ–∂–∏–º
    - –î–ª—è **–ø–µ–π–∑–∞–∂–µ–π** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Real-ESRGAN
    - –ú–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ñ–∞–π–ª—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –ø–∞–ø–∫—É `models/`
    """)

# –§—É—Ç–µ—Ä
st.divider()
st.markdown("""
<div style="text-align: center; color: #666; padding: 20px;">
    <p>¬© 2024 AI Photo Enhancer Pro | –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏</p>
    <p>Real-ESRGAN + –ö–∞—Å—Ç–æ–º–Ω–∞—è CNN | Streamlit Cloud</p>
</div>
""", unsafe_allow_html=True)
