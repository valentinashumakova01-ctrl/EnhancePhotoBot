import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
import numpy as np
import io
import urllib.request
from pathlib import Path
import time
import math

st.set_page_config(
    page_title="RealESRGAN - –¢–æ—á–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞",
    page_icon="üéØ",
    layout="wide"
)

st.title("üéØ RealESRGAN - –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å")
st.markdown("–¢–æ—á–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏")

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
MODEL_DIR = Path("models")
MODEL_DIR.mkdir(exist_ok=True)
MODEL_PATH = MODEL_DIR / "realesrgan_x4plus.pth"

# –¢–û–ß–ù–ê–Ø –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
class ResidualDenseBlock(nn.Module):
    def __init__(self, num_feat=64, num_grow_ch=32):
        super(ResidualDenseBlock, self).__init__()
        self.conv1 = nn.Conv2d(num_feat, num_grow_ch, 3, 1, 1)
        self.conv2 = nn.Conv2d(num_feat + num_grow_ch, num_grow_ch, 3, 1, 1)
        self.conv3 = nn.Conv2d(num_feat + 2 * num_grow_ch, num_grow_ch, 3, 1, 1)
        self.conv4 = nn.Conv2d(num_feat + 3 * num_grow_ch, num_grow_ch, 3, 1, 1)
        self.conv5 = nn.Conv2d(num_feat + 4 * num_grow_ch, num_feat, 3, 1, 1)
        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)

    def forward(self, x):
        x1 = self.lrelu(self.conv1(x))
        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))
        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))
        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))
        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))
        return x5 * 0.2 + x

class RRDB(nn.Module):
    def __init__(self, num_feat, num_grow_ch=32):
        super(RRDB, self).__init__()
        self.rdb1 = ResidualDenseBlock(num_feat, num_grow_ch)
        self.rdb2 = ResidualDenseBlock(num_feat, num_grow_ch)
        self.rdb3 = ResidualDenseBlock(num_feat, num_grow_ch)

    def forward(self, x):
        out = self.rdb1(x)
        out = self.rdb2(out)
        out = self.rdb3(out)
        return out * 0.2 + x

class RealESRGAN(nn.Module):
    """–¢–û–ß–ù–ê–Ø –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ"""
    def __init__(self, num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4):
        super(RealESRGAN, self).__init__()
        self.scale = scale
        
        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)
        
        self.body = nn.ModuleList()
        for _ in range(num_block):
            self.body.append(RRDB(num_feat, num_grow_ch))
        
        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        
        # –ö–æ–Ω–≤–æ–ª—é—Ü–∏–∏ –¥–ª—è upsampling (—Ç–æ—á–Ω—ã–µ –∏–º–µ–Ω–∞ –∫–∞–∫ –≤ –≤–µ—Å–∞—Ö)
        if scale == 4:
            self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
            self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
            self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
            self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)
        elif scale == 2:
            self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
            self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)
        
        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)

    def forward(self, x):
        feat = self.lrelu(self.conv_first(x))
        
        body_feat = feat
        for block in self.body:
            body_feat = block(body_feat)
        body_feat = self.lrelu(self.conv_body(body_feat))
        feat = feat + body_feat
        
        if self.scale == 4:
            # –ü–µ—Ä–≤—ã–π upsampling
            feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))
            # –í—Ç–æ—Ä–æ–π upsampling
            feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))
            feat = self.lrelu(self.conv_hr(feat))
            out = self.conv_last(feat)
        elif self.scale == 2:
            feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))
            out = self.conv_last(feat)
        else:
            out = feat
            
        return out

@st.cache_resource
def download_and_load_model():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ—Å–∞"""
    model_url = "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth"
    
    if not MODEL_PATH.exists():
        with st.spinner("–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤ RealESRGAN (1.07GB)..."):
            try:
                urllib.request.urlretrieve(model_url, MODEL_PATH)
                st.success("‚úÖ –í–µ—Å–∞ —Å–∫–∞—á–∞–Ω—ã!")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
                return None
    
    try:
        st.info("–ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤...")
        state_dict = torch.load(MODEL_PATH, map_location='cpu')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–ª—é—á–∏
        if 'params_ema' in state_dict:
            weights = state_dict['params_ema']
        else:
            weights = state_dict
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –¢–û–ß–ù–´–ú–ò –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
        model = RealESRGAN(
            num_in_ch=3,
            num_out_ch=3,
            num_feat=64,
            num_block=23,
            num_grow_ch=32,
            scale=4
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        model.load_state_dict(weights, strict=True)
        model.eval()
        
        st.success("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        return model
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤: {e}")
        
        # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å—Ç—Ä–æ–≥—É—é –∑–∞–≥—Ä—É–∑–∫—É
        try:
            st.info("–ü–æ–ø—ã—Ç–∫–∞ –Ω–µ—Å—Ç—Ä–æ–≥–æ–π –∑–∞–≥—Ä—É–∑–∫–∏...")
            model.load_state_dict(weights, strict=False)
            st.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (–Ω–µ—Å—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º)")
            return model
        except:
            return None

def process_with_tiling(model, image, tile_size=256, overlap=32):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å tiling –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏"""
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy
    img_np = np.array(image).astype(np.float32) / 255.0
    h, w = img.shape[:2]
    
    # –í—ã—á–∏—Å–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä
    out_h, out_w = h * 4, w * 4
    
    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π –º–∞—Å—Å–∏–≤
    output = np.zeros((out_h, out_w, 3), dtype=np.float32)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Ç–∞–π–ª—ã
    tiles_x = math.ceil(w / tile_size)
    tiles_y = math.ceil(h / tile_size)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i in range(tiles_y):
        for j in range(tiles_x):
            # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–∞–π–ª–∞
            x1 = j * tile_size
            y1 = i * tile_size
            x2 = min(x1 + tile_size, w)
            y2 = min(y1 + tile_size, h)
            
            status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–ª–∞ {i*tiles_x + j + 1}/{tiles_x * tiles_y}")
            
            if (x2 - x1) > 0 and (y2 - y1) > 0:
                # –í—ã—Ä–µ–∑–∞–µ–º —Ç–∞–π–ª
                tile = img_np[y1:y2, x1:x2]
                
                # –î–æ–±–∞–≤–ª—è–µ–º overlap
                tile_padded = np.pad(tile, 
                                   ((overlap, overlap), 
                                    (overlap, overlap), 
                                    (0, 0)), 
                                   mode='reflect')
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ tensor
                tile_tensor = torch.from_numpy(tile_padded).permute(2, 0, 1).unsqueeze(0).float()
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                with torch.no_grad():
                    tile_output = model(tile_tensor)
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ
                tile_output_np = tile_output.squeeze().permute(1, 2, 0).cpu().numpy()
                
                # –£–±–∏—Ä–∞–µ–º overlap (—É–º–Ω–æ–∂–∞–µ–º –Ω–∞ 4 —Ç.–∫. scale=4)
                tile_output_cropped = tile_output_np[overlap*4:-overlap*4, overlap*4:-overlap*4]
                
                # –ö–æ–ø–∏—Ä—É–µ–º –≤ –≤—ã—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                output[y1*4:y2*4, x1*4:x2*4] = tile_output_cropped
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            progress = (i * tiles_x + j + 1) / (tiles_x * tiles_y)
            progress_bar.progress(progress)
    
    progress_bar.empty()
    status_text.empty()
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL
    output = np.clip(output, 0, 1) * 255
    return Image.fromarray(output.astype(np.uint8))

def main():
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    tile_size = st.sidebar.selectbox("–†–∞–∑–º–µ—Ä —Ç–∞–π–ª–∞", [128, 192, 256], index=1)
    use_tiling = st.sidebar.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å tiling", True, 
                                     help="–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    with st.spinner("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏..."):
        model = download_and_load_model()
    
    if model is None:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
        return
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    col1, col2 = st.columns(2)
    
    with col1:
        st.header("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ")
        
        uploaded = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
            type=['jpg', 'png', 'jpeg'],
            help="–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ 512x512 –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"
        )
        
        if uploaded:
            input_img = Image.open(uploaded).convert('RGB')
            
            # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä
            max_preview = 512
            if max(input_img.size) > max_preview:
                ratio = max_preview / max(input_img.size)
                preview_size = (int(input_img.size[0] * ratio), 
                              int(input_img.size[1] * ratio))
                preview_img = input_img.resize(preview_size, Image.Resampling.LANCZOS)
            else:
                preview_img = input_img
            
            st.image(preview_img, caption=f"–û—Ä–∏–≥–∏–Ω–∞–ª: {input_img.size}", width=300)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            st.info(f"""
            **–î–µ—Ç–∞–ª–∏:**
            - –†–∞–∑–º–µ—Ä: {input_img.size[0]} √ó {input_img.size[1]}
            - –í—ã—Ö–æ–¥: {input_img.size[0]*4} √ó {input_img.size[1]*4}
            - –ü–∞–º—è—Ç—å: ~{(input_img.size[0]*input_img.size[1]*3*4)/1024/1024:.1f} MB
            """)
    
    with col2:
        st.header("‚ú® –†–µ–∑—É–ª—å—Ç–∞—Ç")
        
        if uploaded and 'input_img' in locals():
            if st.button("üöÄ –£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ 4x", type="primary", use_container_width=True):
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ RealESRGAN..."):
                    start_time = time.time()
                    
                    try:
                        if use_tiling and (input_img.size[0] > 256 or input_img.size[1] > 256):
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º tiling –¥–ª—è –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                            enhanced = process_with_tiling(model, input_img, 
                                                         tile_size=tile_size, 
                                                         overlap=32)
                        else:
                            # –ü—Ä—è–º–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö
                            img_np = np.array(input_img).astype(np.float32) / 255.0
                            img_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).float()
                            
                            with torch.no_grad():
                                output_tensor = model(img_tensor)
                            
                            output_np = output_tensor.squeeze().permute(1, 2, 0).cpu().numpy()
                            output_np = np.clip(output_np, 0, 1) * 255
                            enhanced = Image.fromarray(output_np.astype(np.uint8))
                        
                        elapsed = time.time() - start_time
                        
                        # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                        if max(enhanced.size) > max_preview:
                            ratio = max_preview / max(enhanced.size)
                            preview_size = (int(enhanced.size[0] * ratio), 
                                          int(enhanced.size[1] * ratio))
                            preview_enhanced = enhanced.resize(preview_size, Image.Resampling.LANCZOS)
                        else:
                            preview_enhanced = enhanced
                        
                        st.image(preview_enhanced, caption=f"–£–ª—É—á—à–µ–Ω–æ: {enhanced.size}", width=300)
                        
                        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ
                        buf = io.BytesIO()
                        enhanced.save(buf, format="PNG", optimize=True)
                        
                        st.download_button(
                            "üì• –°–∫–∞—á–∞—Ç—å PNG",
                            buf.getvalue(),
                            file_name=f"real_esrgan_{uploaded.name}",
                            mime="image/png",
                            use_container_width=True
                        )
                        
                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                        st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ {elapsed:.1f} —Å–µ–∫—É–Ω–¥")
                        
                        col_stat1, col_stat2 = st.columns(2)
                        with col_stat1:
                            st.metric("–í—Ö–æ–¥", f"{input_img.size[0]}√ó{input_img.size[1]}")
                        with col_stat2:
                            st.metric("–í—ã—Ö–æ–¥", f"{enhanced.size[0]}√ó{enhanced.size[1]}", delta="4x")
                        
                    except torch.cuda.OutOfMemoryError:
                        st.error("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ GPU! –£–≤–µ–ª–∏—á—å—Ç–µ —Ä–∞–∑–º–µ—Ä —Ç–∞–π–ª–∞ –∏–ª–∏ —É–º–µ–Ω—å—à–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
                    except RuntimeError as e:
                        if "out of memory" in str(e).lower():
                            st.error("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
                            st.markdown("""
                            1. –£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ç–∞–π–ª–∞
                            2. –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–µ–Ω—å—à–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                            3. –í–∫–ª—é—á–∏—Ç—å tiling
                            """)
                        else:
                            st.error(f"–û—à–∏–±–∫–∞: {e}")
        
        else:
            st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    with st.expander("üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏"):
        st.markdown(f"""
        ### RealESRGAN_x4plus
        
        **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
        - –ë–ª–æ–∫–∏: 23 RRDB
        - –ö–∞–Ω–∞–ª—ã: 64 (num_feat)
        - –†–æ—Å—Ç –∫–∞–Ω–∞–ª–æ–≤: 32 (num_grow_ch)
        - –ú–∞—Å—à—Ç–∞–±: 4x
        
        **Tiling —Å–∏—Å—Ç–µ–º–∞:**
        - –†–∞–∑–º–µ—Ä —Ç–∞–π–ª–∞: {tile_size}px
        - Overlap: 32px
        - –û–±—Ä–∞–±–æ—Ç–∫–∞: –ø–æ —á–∞—Å—Ç—è–º
        
        **–ü–∞–º—è—Ç—å:**
        - –í–µ—Å–∞ –º–æ–¥–µ–ª–∏: 1.07GB
        - –ü–∞–º—è—Ç—å –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É: ~500MB-1GB
        - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ 512x512
        """)

if __name__ == "__main__":
    main()
